# -*- coding: utf-8 -*-
"""ANLP_Baseline1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gG49fzvnKnsTgQEgvrblSQTw1E5iHt_g
"""

# Install necessary packages
!pip install datasets
!pip install sentencepiece
!pip install transformers==4.21.3

# Import the dataset
import torch
from datasets import load_dataset
answersumm = load_dataset("alexfabbri/answersumm")

all_full_answers = []

for answer in answersumm["train"][1]["answers"]:
    full_answer = []

    for sentence in answer['sents']:
        full_answer.append(sentence["text"])

    fullanswer = " ".join(full_answer)
    all_full_answers.append(fullanswer)
    # print(fullanswer, end="\n\n")

passage = ""
for summary in all_full_answers:
    passage = passage + summary + " "
passage = passage[:-1]
passage

# # Prepare a text to summarize
# ARTICLE = ""
# count = 0
# for word in passage.split(" "):
#   if count < 300:
#     ARTICLE = ARTICLE + word + " "
#   else:
#     break
#   count = count + 1

# # Pegasus-Google Model
# from transformers import PegasusTokenizer, PegasusForConditionalGeneration

# model = PegasusForConditionalGeneration.from_pretrained("google/pegasus-xsum")
# tokenizer = PegasusTokenizer.from_pretrained("google/pegasus-xsum")

# inputs = tokenizer(passage[:-1], truncation=True, padding="longest", return_tensors="pt")

# # Generate Summary
# summary = model.generate(**inputs)
# tokenizer.decode(summary[0])

# t5-base Model
from transformers import pipeline

summarizer = pipeline("summarization", model="t5-base", tokenizer="t5-base", framework="tf")
summary_text = summarizer(passage[:-1], truncation=True, model_max_length=512, max_length=100, min_length=5, do_sample=False)[0]['summary_text']
print(summary_text)

# Get the summary of the text from the dataset
summaries = []

for summary in answersumm["train"]["summaries"][1]:
    full_summary = []

    for sentence in summary:
        full_summary.append(sentence)

    fullsummary = " ".join(full_summary)
    summaries.append(fullsummary)
    # print(fullanswer, end="\n\n")

reference_text = summaries[0]
reference_text

!pip install rouge

# Calculate the ROUGE scores for the different summaries
from rouge import Rouge
rouge = Rouge()

rouge.get_scores(summary_text, reference_text)

# Initialise parameters
MAX_COUNT = 10

# Extract the questions
questions = []
for i in range(MAX_COUNT):
  all_full_answers = []
  for answer in answersumm["train"][i]["answers"]:
    full_answer = []

    for sentence in answer['sents']:
      full_answer.append(sentence["text"])

    fullanswer = " ".join(full_answer)
    all_full_answers.append(fullanswer)

  passage = ""
  for summary in all_full_answers:
    passage = passage + summary + " "

  questions.append(passage[:-1])

# Extract the corresponding summaries
summaries = []
for i in range(MAX_COUNT):
  for summ in answersumm["train"]["summaries"][i]:
    full_summary = []

    for sentence in summ:
      full_summary.append(sentence)

    fullsummary = " ".join(full_summary)
  summaries.append(fullsummary)

# Run the model
model_text = []
for i in range(MAX_COUNT):
  summary_text = summarizer(questions[i], truncation=True, max_length=100, min_length=5, do_sample=False)[0]['summary_text']
  model_text.append(summary_text)

# Calculate Rouge Scores
avg_r1 = 0
avg_r2 = 0
avg_rl = 0
for i in range(MAX_COUNT):
  scores = rouge.get_scores(model_text[i], summaries[i])
  avg_r1 += scores[0]["rouge-1"]['f']
  avg_r2 += scores[0]["rouge-2"]['f']
  avg_rl += scores[0]["rouge-l"]['f']
           

avg_r1 = avg_r1 * 100.0 / MAX_COUNT
avg_r2 = avg_r2 * 100.0 / MAX_COUNT
avg_rl = avg_rl * 100.0 / MAX_COUNT
avg_r1,avg_r2,avg_rl

(23.692273231399177, 5.469238016706818, 19.798875085594204)